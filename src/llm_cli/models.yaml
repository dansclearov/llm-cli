# Model capabilities configuration
# Defaults: supports_search=false, supports_thinking=false, max_tokens=null

# Centralized model aliases
aliases:
  # Default model (used when no -m provided)
  default: gpt-4o
  
  # Meaningful aliases only (where alias != model name)
  sonnet: anthropic/claude-sonnet-4-20250514
  opus: anthropic/claude-opus-4-20250514
  gpt-4o: openai/chatgpt-4o-latest
  gpt-4.5: openai/gpt-4.5-preview
  r1: deepseek/deepseek-reasoner
  r1-free: "openrouter/deepseek/deepseek-r1-0528:free"
  kimi: openrouter/moonshotai/kimi-k2
  grok-4: openrouter/x-ai/grok-4

anthropic:
  claude-sonnet-4-20250514:
    supports_search: false
    supports_thinking: false
    max_tokens: 8192
    
  claude-opus-4-20250514:
    supports_search: false
    supports_thinking: false
    max_tokens: 8192

openai:
  chatgpt-4o-latest: {}
    
  gpt-4.5-preview: {}
    
  gpt-4-turbo: {}
    
  o4-mini:
    supports_thinking: true
    
  o3:
    supports_thinking: true

deepseek:
  deepseek-reasoner:
    supports_thinking: true

xai:
  grok-3:
    supports_search: true

gemini:
  gemini-2.5-pro: {}
    
  gemini-2.5-flash: {}

# OpenRouter quantization configuration (YAML anchor for reuse)
_openrouter_min_fp8: &openrouter_min_fp8
  provider:
    quantizations: ["fp8", "fp16", "bf16", "fp32", "unknown"]

openrouter:
  "deepseek/deepseek-r1-0528:free":
    supports_thinking: true
    extra_params:
      <<: *openrouter_min_fp8
    
  moonshotai/kimi-k2:
    extra_params:
      <<: *openrouter_min_fp8
    
  x-ai/grok-4: {}
    # TODO: implement search for openrouter
    # supports_search: true