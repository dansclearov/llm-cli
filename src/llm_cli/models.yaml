# Model capabilities configuration
# Defaults: supports_search=false, supports_thinking=false, max_tokens=null

# Centralized model aliases
aliases:
  # Default model (used when no -m provided)
  default: gpt-4o
  
  # Meaningful aliases only (where alias != model name)
  sonnet: anthropic/claude-sonnet-4-5-20250929
  opus: anthropic/claude-opus-4-1-20250805
  gpt-4o: openai/chatgpt-4o-latest
  gpt-4.5: openai/gpt-4.5-preview
  r1: deepseek/deepseek-reasoner
  r1-free: "openrouter/deepseek/deepseek-r1-0528:free"
  kimi: openrouter/moonshotai/kimi-k2-0905
  qwen3-max: openrouter/qwen/qwen3-max
  grok-4: openrouter/x-ai/grok-4

anthropic:
  claude-sonnet-4-5-20250929:
    supports_search: true
    supports_thinking: false
    max_tokens: 8192

  claude-sonnet-4-20250514:
    supports_search: true
    supports_thinking: false
    max_tokens: 8192

  claude-opus-4-1-20250805:
    supports_search: true
    supports_thinking: false
    max_tokens: 8192

openai:
  chatgpt-4o-latest: {}

  gpt-4.5-preview: {}

  gpt-4-turbo: {}

  gpt-5:
    supports_thinking: true
    supports_search: true

  o4-mini:
    supports_thinking: true
    supports_search: true

  o3:
    supports_thinking: true
    supports_search: true

deepseek:
  deepseek-reasoner:
    supports_thinking: true

xai:
  grok-3:
    supports_search: true

gemini:
  gemini-2.5-pro: {}
    
  gemini-2.5-flash: {}

# OpenRouter quantization configuration (YAML anchor for reuse)
_openrouter_min_fp8: &openrouter_min_fp8
  provider:
    quantizations: ["fp8", "fp16", "bf16", "fp32", "unknown"]

# TODO: implement search for openrouter
openrouter:
  "deepseek/deepseek-r1-0528:free":
    supports_thinking: true
    extra_params:
      <<: *openrouter_min_fp8
    
  moonshotai/kimi-k2-0905:
    extra_params:
      <<: *openrouter_min_fp8

  x-ai/grok-4: {}

  qwen/qwen3-max: {}

